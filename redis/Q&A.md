#### redis常见性能问题与解决方案？

- master最好不要做任何的持久化工作，Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务.AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度；
- 如果数据比较重要，某个slave开始AOF备份数据，策略设置为每秒同步1次；
- 为了主从复制的速度和连接的稳定性，master和slave最好在同一个局域网内；
- 尽量避免在压力很大的主库上增加从库；
- 主从复制不要使用图状结构，用单向链表结构更为稳定，即：master <- slave1 <- slave2 <- slave3 ... ，这样的结构更方便解决单点故障问题，实现slave对master的替换。如果master挂了，可以立即启用slave1做master，其他不变

#### 为什么Redis不建议key太长，原理

太长的键值不是个好主意，例如1024字节的键值就不是个好主意，不仅因为消耗内存，而且在数据中查找这类键值的计算成本很高

#### bigkey的危害



#### 布隆过滤器的实现机制

布隆过滤器本质是一个巨大的bit数组（bit array）+几个不同的无偏hash函数。

  布隆过滤器添加一个item("testbf")，其操作步骤是：

- 使用多个无偏哈希函数对item进行hash运算，得到多个hash值hash(testbf)；
- 每个hash值对bit数组取模得到位数组中的位置index(testbf)；
- 判断所有index位是否都为1 ；
- 位都为1则说明该元素可能已经存在了；
- 任意一位不为1则说明一定不存在，此时会将不为1的位置为1；

#### 一个Redis实例最多能存放多少的keys

理论上Redis可以处理多达2^32的keys,在实际中进行了测试，每个实例至少存放了2亿5千万的keys

#### aof 如果文件越来愈大 怎么办

当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上

#### redis 采用 aof 持久化时，数据是先写入内存，还是先写入日志，为什么

Redis 是先执行命令，把数据写入内存，然后才记录日志。保证数据执行报错，以及不阻塞当前操作

#### redis多数据库机制

单机情况下可支持16个数据库（db-~db15）.custer下只有一个一个数据库空间

#### 怎么理解Redis事务

redis 的事务是非原子性。生产上采用的是Redis Cluster集群架构，不同的key是有可能分配在不同的Redis节点上的，在这种情况下Redis的事务机制是不生效的。其次，Redis事务不支持回滚操作，所以基本不用

相关命令：

- muti:开启事务，redis会将后续的命令逐个放入队列中，然后使用**EXEC命令来原子化**执行这个命令系列。
- exec:执行事务中的所有操作命令
- discard：取消事务
- watch:监视一个或多个key.如果事务MULTI**前**，该key被其他命令修改，则事务中断，不会执行任何命令
- unwatch:取消对key的监视

事务的失败处理：

- 语法错误（编译错误）：命令中语法有问题，所有都不更改
- 运行时错误：跳过错误继续执行，已变化的保存变化值

#### redis cluster 下如何执行批量操作

不同的key会被划分到不同的slot,所以mset这些批量操作行不通。

如果真要执行，key数量少的情况下就用串行操作。key如果多，使用hashtag保证key映射到同一redis

#### hashtag

对于key为{foo}.key1、{foo}.key2，{foo}.key3，这类key一定是在同一个redis节点上。因为key中“{}”之间的字符串就是当前key的hash tags， 只有key中{ }中的部分才被用来做hash，因此计算出来的redis节点一定是同一个

#### 读写分离一定能提升性能么

使用cluster架构属于分片集群的架构，redis本身属于内存操作，不涉及IO吞吐，即使读写分离也不一定能体色韩国你太多性能，redis在生产上主要问题考虑容量，单机最多10-20G.key太多降低redis性能，采用分片集群架构已经保证了性能，用上读写分离后，还要考虑主从一致性问题，主从延迟问题，让业务复杂化

#### 缓存异常

缓存穿透：获取不存在的数据。

请求校验或布隆过滤器或将查询为null的结果缓存起来，过期事件设置很短

缓存击穿：大量访问热点数据，热点突然失效，导致直接大量访问到数据库

互斥锁或热点永不过期

缓存雪崩：缓存的数据大批失效，大量的缓存击穿，导致数据库宕机

过期时间的基础上随机添加一个随机数，让过期时间分散开   或  热点永不过期  或加锁排队

#### redis 与数据库双写一致性如何保证

##### 经典模式：cashe aside pattern

读：先缓存，没有读数据库，然后放入缓存

写：先数据库，然后删除缓存

##### 为什么删除缓存不是更新缓存：

更新了一个字段，其对应的缓存很多时候不单是从数据库取的值，需要多表查询计算得来，更新缓存的代价有点高，而且该缓存比一定被频繁访问到。所以直接删除缓存，有需要再去缓存

**问题：**如果删除缓存失败会导致缓存中是旧数据，出现不一致

**解决方案：**先删除缓存再更新数据库。即便数据库失败，那么读取时，缓存为空，读取数据库中的旧数据，更新到缓存中。

##### 先删除缓存再更新数据库

问题：高并发的情况下，如果先删除缓存，还没更新数据库时，一个请求去读取缓存，读取数据库旧数据到缓存中，而此时更新了数据库。

**解决方案：**延时双删策略。先del redis,再写数据库，sleep(),再删除缓存

如果mysql用了读写分离，因为从库读取binlog会导致数据延迟，在从库还没更新的时候读取旧数据，也会造成不一致，还是使用双删策略，睡眠时间修改为在主从同步的基础上再加几百毫秒。

#### redis强一致性么，怎么保证强一致性，有什么方案

（最终一致性和强一致性）

如果对数据有强一致性要求，**读请求和写请求串行化**，串到一个**内存队列**里去。但是降低了吞吐量

#### Redis集群最大节点个数是多少

16384 个。原因如下：

Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 算法计算的结果，对 16384 取模后放到对应的编号在 0-16383 之间的哈希槽，集群的每个节点负责一部分哈希槽

#### 为什么是16384个？

**1.如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。**

如上所述，在消息头中，最占空间的是 `myslots[CLUSTER_SLOTS/8]`。 当槽位为65536时，这块的大小是: `65536÷8÷1024=8kb`因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。

**2.redis的集群主节点数量基本不可能超过1000个。**

如上所述，集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。

**3.槽位越小，节点少的情况下，压缩率高**

Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。

而16384÷8÷1024=2kb，怎么样，神奇不！

综上所述，作者决定取16384个槽，不多不少，刚刚好

引用：	

#### Redis集群会有写操作丢失吗？为什么

以下情况可能导致写操作丢失：
1、过期 key 被清理。
2、最大内存不足，导致 Redis 自动清理部分 key 以节省空间。
3、主库故障后自动重启，从库自动同步。
4、单独的主备方案，网络不稳定触发哨兵的自动切换主从节点，切换期间会有数据丢失

#### redis 内存模型

参考：https://www.cnblogs.com/kismetv/p/8654978.html

#### redis线程模型

- 文件事件处理器

redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件

redis单线程模型中最为核心的就是文件事件处理器。文件事件处理器的结构包含4个部分：多个socket，IO多路复用程序，socket队列，文件事件分派器，事件处理器（命令请求处理器、命令回复处理器、连接应答处理器，等等）

![img](..\image\redis\文件事件处理器.png)

- 文件事件

客户端对redis执行read操作，socket会产生一个AE_WRITABLE事件。

对redis进行read操作时，socket会产生一个AE_READABLE事件

又有read和write,同时产生两种事件。文件事件分派其优先处理AE_REABLE事件，然后才是AE_WRITABLE事件

#### 分布式寻址都有哪些算法？ | key 寻址算法有哪些

- **hash 算法（大量缓存重建）**：hash(key)%len(master).当master数量变化，会根据最新的master数量取模。导致很多key无法找到缓存，导致大量数据流入数据库
- **一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）**：一致性hash算法将整个 hash 值空间组织成一个虚拟的圆环。按照顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。来一个key后,根据hash值确定环上位置，从此位置顺时针走，遇上的第一个节点就是key所在位置。如果一个节点挂掉，最多只会影响此节点到前一节点的数据。但是master节点太少会出现缓存热点问题，为了解决这一问题，引入了虚拟节点。会对一个节点进行多次hash，每个hash结果放置一个位置。实现了数据均匀分布

- **redis cluster 的 hash slot 算法**：redis cluster 有固定的 `16384` 个 hash slot，对每个 `key` 计算 `CRC16` 值，然后对 `16384` 取模，可以获取 key 对应的 hash slot。每个节点持有一部分slot.当一个节点宕机，他的slot会迁移到其他机器。而key寻找的是hashsolt  而不是节点。

#### redis 集群模式的工作原理

redis cluster，主要是针对海量数据+高并发+高可用的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。

redis cluster架构下，每个redis开放两个端口，6379和16379.

16379是用来进行节点之间的通信，也就是cluster bus的通讯，用来检测故障，配置更新，故障转移。采用二进制的gossip协议，用来减少带宽，更高效进行数据交换。

gssip协议，每个节点都持有一份数据，不同节点如果出现数据变更，不断的将变更也发给其他节点，让其他节点也进行数据变更

gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

#### 缓存集群如何扩容

通过Hash卡槽来唯一确定每一个Key存放的Redis主机，实现Redis动态扩容和缩容。redis集群在提供服务期间，动态新增redis片区（redis master+cluster）,把已经分配slot的redis主机的slot数据迁移一部分到新的机器上。实现扩容。

举例：原有masterA,B,C.新增master支持的最大卡槽阀值指定的是4098。原集群中的solt分布为：msterA[0-5460] 	masterB[5461-10921]	masterC[10922-16382].

三台主机需要迁移的slot数= 4093/3=1366

扩容后，四台主机对应卡槽分布为：msterA[0-4093] 	masterB[5461-9554]	masterC[10922-15015] masterD[4094-5460]+[9555-10921]+[15016-16382].

#### 缩容

redis集群在提供服务期间，动态删除redis片区（redis master+cluster）,把删除的redis主机的slot数据还原到其他master上。和扩容相反

#### 如何判断节点宕机

一个节点认为另一个节点宕机，此时是pfail.主观宕机，如果超过多数节点都认为那个节点宕机，称为fail，客观宕机。

在 cluster-node-timeout 内，某个节点一直没有返回 ping，那么就被认为 pfail。

如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail

#### 节点选举

类似kafka,每个slave都会记录从master复制数据的offset,根据offset设置一个选举时间，offset越大，选举时间越靠前，越优先选举。所有的master给要选举的slave，如果（N/2+1）都投个了某个slave,那么选举通过。从变主

#### 系统在10：05 设置一个值，并给出5分钟的过期时间，系统刚刚set完之后redis集群崩溃，10：11分系统重启成功，那么redis中set的值是否还存在

**考察点：**

1、redis 的持久化：刚set完是否能够被持久化到快照或者binlog日志中；

2、假设redis被持久化，且系统重启时间超过了redis设置的过期时间，那么key是否会被清理

#### redis删除机制

redis 采用定期删除+惰性删除策略

定期删除：默认每100ms检查是否有过期的key,有则删除。删除也只是随机抽取进行检查。

定期随机删除无法删除完全，于是惰性删除上场了。get时检查是否过期，过期此时就删除。

#### 定期删除+惰性删除完全ok?

定期没有删除的key，也一直没有get.那key越来越多。这时就应该采用内存淘汰机制。内存不足时，新写入key时，可以选择下列删除key

noeviction：报错

allkeys-lru:最少使用的可以被删除

allkeys-random:随机删除key

volatile-lru:所有设置过期时间的key中的，最少使用的key删除

volatile-ttl:所有设置过期时间的key中的,最早过期的key优先删除

#### 为什么不用定时删除策略？：

定时删除，用一个定时器来负责监视key，当这个key过期就自动删除，虽然内存及时释放，但是十分消耗CPU资源，在大并发请求下CPU要尽可能的把时间都用在处理请求，而不是删除key，因此没有采用这一策略

#### redis的持久性方式

RDB持久化方式会在特定的间隔保存那个时间点的数据快照。AOF持久化方式则回记录每个服务器收到的写操作。默认是RDB。也可以是一种方式也可以是两种结合方式。

#### 





































