#### MR中自定义counter

定义counter名称

```
public enum MyCounter {
    NEW_COUNTER;
}
```

mapper中使用counter

```
context.getCounter(MyCounter.NEW_COUNTER).increment(1);
```

driver中查看counter

```
Counter nyCounter=counters.findCounter(MyCounter.NEW_COUNTER);
log.info(nyCounter.getName() + " num is " + nyCounter.getValue());
```

#### 2020-3-18 字符串引用

```
        List<String> list = new ArrayList<>();
        list.add("asdf");
        for (String s : list) {
            s = "jioas";
        }
        System.out.println(list);//期待jioas。结果输出asdf
```

#### 值传递

```
    public static void main(String[] args) {
        int num = 10;
        changeValue(num);
        System.out.println("main:num="+num); // ?
    }
    public static void changeValue(int num) {
        num = 5;
        System.out.println("changeValue:num="+num); // ?
    }
//    输出结果
//    changeValue:num=5
//    main:num=10
```

每个方法被调用都会在栈内存中。一个方法一个栈帧。栈帧中存储着该方法的局部变量表。

调用main方法的时候，num=10.调用changeValue方法时num的值复制给了changeValue的num.但是和main方法是独立的。changeValue运行时将值改成5，结束该内存消失，所以main中num还是10.

引用传递

```
    static class User{
        int id ;
    }
    public static void main(String[] args) {
        User user = new User();
        user.id = 10;
        changeValue(user);
        System.out.println("main:num="+user.id); // ?
    }
    public static void changeValue(User user) {
        user.id = 5;
        System.out.println("changeValue:num="+user.id); // ?
    }
//    输出结果
//    changeValue:num=5
//    main:num=5
```

- 调用main方法时,在栈内存中开启了一块main方法使用的内存空间,里面有个叫user的变量,该变量存入的是堆内存中User对象的内存地址,假设该地址是:0xabc,0xabc地址中有块叫id的内存空间,用于存储id的值
- 调用changeValue方法时,把main方法中u变量存储的值复制了一份传递给了changeValue方法中的u变量,此时changeValue方法中num变量的值也是0xabc,同理main方法中的u变量和changeValue方法中的u变量也是相互独立的两个空间
- changeValue方法中把堆内存上0xabc地址中id的变量的值改成5,然后再访问0xabc地址中id空间的值,当然打印出来是5,然后changeValue方法结束,同样该栈帧销毁
- 在main方法中也再次访问0xabc地址中id的变量的值,该值在之前的changeValue方法中已经被改成了5,所以在main方法也打印出来的结果自然也是5啦

#### 常量池

https://www.imooc.com/article/68981

https://www.jianshu.com/p/cf78e68e3a99

#### 字符串常量池时什么？

> 在 HotSpot VM 里实现的 string pool 功能的是一个 StringTable 类，它是一个 Hash 表，默认值大小长度是1009；里面存的是驻留字符串的引用（而不是驻留字符串实例自身）。也就是说某些普通的字符串实例被这个 StringTable 引用之后就等同被赋予了“驻留字符串”的身份。这个 StringTable 在每个 HotSpot VM 的实例里只有一份，被所有的类共享。
>
> StringTable 本质上就是个 `HashSet<String>`。这是个纯运行时的结构，而且是惰性（lazy）维护的。注意它只存储对java.lang.String 实例的引用，而不存储 String 对象的内容。 注意，它只存了引用，根据这个引用可以得到具体的 String 对象。
>
> 在 JDK6.0 中，StringTable 的长度是固定的，长度就是 1009，因此如果放入 String Pool 中的 String 非常多，就会造成 hash 冲突，导致链表过长，当调用 String#intern() 时会需要到链表上一个一个找，从而导致性能大幅度下降；
>
> 在 JDK7.0 中，StringTable 的长度可以通过参数指定：
>
> ```text
> -XX:StringTableSize=66666
> ```
>
> https://zhuanlan.zhihu.com/p/107776367

#### 通过nginx实现打点记录

定义格式

```
log_format dot_str escape=json '$time_local - $page- $content';
```

在server中过滤数据

```
server {
    set $version '';
    set $content '';
        location /dotting/pc {
            content_by_lua '
                function read_from_file(file_name)
                    local f = assert(io.open(file_name, "r"))
                    local string = f:read("*all")
                    f:close()
                    return string
                end
                local args = ngx.req.get_uri_args()
                ngx.var.page = args["page"]
                local request_method = ngx.var.request_method
                if request_method == "GET" then
                    ngx.var.content = args["content"]
                elseif request_method == "POST" then
                    ngx.req.read_body()
                    local body_str = ngx.req.get_body_data()
                    if nil == body_str then
                        local body_file = ngx.req.get_body_file()
                        if body_file then
                            body_str = read_from_file(body_file)
                        end
                    end
                    ngx.var.content = body_str
                end
            ';
            access_log /data/nginx/logs/pc/dotting.log dot_str;
        }          
	}
}
```

#### 以表见表

CREATE TABLE t_new LIKE t_old

#### 商品库项目总结

将商品存入es选择restful的api的原因：

- 原先的spark-es 写入经常出现数据丢失，因为出现429错误码（too many request）
- 缺少错误处理。dts 可以针对不同的错误码做出不同的处理.ogstash也不能灵活处理
- 不能解决因版本冲突导致的数据覆盖。dts可以使用外部版本解决该问题
  数据
- 效率问题：17万写入耗时100秒（Spark版本180秒），写入速度提升80%。qps最高达到1.2w/s
- 延迟问题：Kafka消费->ES可检索，最短0.1秒，最长4.7秒，平均2.75秒。Spark版本10秒-30秒不等。相对于Spark的短时批量，DTS的实时性更好。
- 废弃了索引url类型字段的无填充即默认0的逻辑，单条索引磁盘占用降低31%。
- 基于线上index的mapping创建规则，不再从配置文件中获取maping
- bulk size 设置在13M  官方建议10-15M。经测试 13M 在该集群中最快

选择pb格式存储的原因：

- 占用内存小。是json的1/5  传输效率更高

去重策略：百万以下使用diff，百万以上使用bf

- bf以上允许存在一定误差，bf的效率远高于diff