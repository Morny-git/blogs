#### 读写速度达到每秒百万级别，如何实现？

1.写入到磁盘中，但是顺序读写。

2.写入采用MMAP(Memory Mapped Files)-内存映射文件。

3.读取使用了基于sendfile的Zero Copy提高Web Server静态文件的速度。传统模式经过了4次copy：硬盘—>内核buf—>用户buf—>socket相关缓冲区—>协议引擎。而sendfile系统调用则是减少了数据复制，还减少了上下文的切换

4.批量压缩，支持多种压缩方式

kafka速度快的原因在于，把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO的损耗，通过MMAP提高I/O的速度。写入数据的时候，由于单个Partition（分区）是末尾添加的所以速度最优；读取数据的时候配合sendfile直接暴力输入

**传统模式**，read/write文件流程：

-  操作系统将数据从磁盘读入到内核空间的页缓存
-  应用程序将数据从内核空间读入到用户空间缓存中
-  应用程序将数据写回到内核空间到socket缓存中
-  操作系统将数据从socket缓冲区复制到网卡缓冲区，以便将数据经网络发出）

![img](..\image\kafka\read.png)

**sendfile**运行流程：

- sendfile系统调用，文件数据被copy至内核缓冲区。
- 再从内核缓冲区copy至内核中socket相关的缓冲区。
- 最后再socket相关的缓冲区copy到协议引擎

#### 压缩算法

2.1.0版本之前，kafka支持3种压缩算法：GZIP、Snappy和LZ4

2.1.0开始，kafka正式支持Zstandard算法(简写zstd)。它是Facebook开源的一个压缩算法，能够提供超高的压缩比。

对于kafka测试而言，在吞吐方面：LZ4>Snappy> zstd、GZIP；

在压缩比方面：zstd>lz4>gzip>snappy。

CPU使用率方面，各个算法表现得差不多，只是在压缩时snappy使用的CPU较多一些，而在解压缩时gzip算法则可能使用更多的CPU

kafka 的消息格式：	消息集合和消息。消息集合包含若干项日志项，日志项才是封装消息的地方。

kafka的消息日志是由一系列消息集合日志项组成。kafka都是在消息集合这个层面上进行写入操作。

#### 什么时候压缩

producer端：指定压缩算法，producer启动后生产的每个消息集合都经过该压缩算法

broker端：producer的压缩算法不一致的话需要先解压再压缩。一致的话则原封不动。或是消息格式发生变化（兼容老版本）

#### 什么时候解压缩

consumer:消费消息时解压缩

broker:除了上述情况，还有一种情况，在broker端需要进行消息认证的时候需要解压缩

#### 批量提交

通过batch.size 和 linger.ms 设置。任意一条件到达都可进行屁来给你提交。linger.ms 默认是0.只要由消息就提交。batch.size 默认是16k,发往同一分区的消息满16K 提交

### 存储机制

kafka的数据存储在磁盘中。通过topic将消息进行分类，每个topic可以分为多个分区partition。partition有多个备份replica  分布在不同的broker,只有replica leader 才会进行消息读写。

每个partition由多个segment组成。segment是在磁盘上就是一对文件，包含index和log文件，两种文件名相同，后缀不同。

每个topic的第一个segment文件都从0开始。segment文件命名规则由20个字符。下一个segment file文件的名字就是，上一个segment file中最后一条消息的索引值。index文件以key-value形式存储，key代表.log中按顺序开始第条消息，value代表该消息的位置偏移。.index中不是对每条消息都做记录，它是每隔一些消息记录一次，避免占用太多内存。

#### 参数

**Broker**：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。

**Topic**：一类消息，Kafka集群能够同时负责多个topic的分发。

**Partition**：topic物理上的分组，一个topic可以分为多个partition，命名规则topic_x.从0 开始。每个partition是一个有序的队列。

**replica**:每个分区中又有多个replica.其中分为一个leader和多个followers.

**Segment**：partition物理上由多个segment组成。

**offset**：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息

#### Partition、Replica、Log 和 LogSegment 的关系

![img](..\image\kafka\patition_repl,png)

Partition和replica分布在不同的broker,如果某个broker宕机，可以将分布在其他broker的replica升级为主副本。

partition的实际物理存储以log文件的形式展示的，而每个log文件又以多个segment组成。一个segment 默认大小是500M，segment由两部分构成，xx.index和xx.log。在服务器上，每个partition是一个文件夹，每个segment是一个文件。这个文件类似于在上面看到的文件存储内容。

#### 删除数据

 kafka数据被消费后虽然不会被立即删除，但不可能一直不删除，kafka根据两个设置定时检测做删除操作

```
1. 基于时间：log.retention.hours=168
2. 基于大小：log.retention.bytes=1073741824
```

 满足任何一个都会删除之前的segment，记住不是删除某一个消息，删除的最小单位是segment

##### 通过offset查找msg

以读取offset=368776的message为例，需要通过如下的步骤进行查找

- 第一步
    第一个00000000000000000000.index 标识最开始的文件，起始偏移量为0，第二个文件00000000000000368769.index 的消息量起始偏移量为368770=368769+1，只要根据offset二分法查找文件列表，就可以快速定位到具体文件，当offset=368776时定位到00000000000000368769.index|log
- 第二步 通过segment file 查找message；
    算出368776-368770=6，取00000000000000368769.index文件第三项(6,1407)，得出从00000000000000368769.log文件头偏移1407字节读取一条消息即可

客户端根据offset写msg

1. 客户端消息收集器收集属于同一个分区的消息，并对每条消息设置一个offset，且每一批消息总是从 0 开始单调递增。比如第一次发送 3 条消息，则对三条消息依次编号 [0,1,2]，第二次发送 4 条消息，则消息依次编号为 [0,1,2,3]。注意此处设置的消息偏移量是相对偏移量。
2. 客户端将消息发送给服务端，服务端拿到下一条消息的绝对偏移量，将传到服务端的这批消息的相对偏移量修改成绝对偏移量。
3. 将修改后的消息以追加的方式追加到当前活跃的 LogSegment 后面，然后更新绝对偏移量。
4. 将消息集写入到文件通道。
5. 文件通道将消息集 flush 到磁盘，完成消息的写入操作

### 写入流程

1. producer 先从 zookeeper 的 "/brokers/.../state" 节点找到该 partition 的 leader
2. producer 将消息发送给该 leader
3. leader 将消息写入本地 log
4.  followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK
5.  leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK

### 读取流程

1. 连接到zk,从zk中拿到对应topic的partition信息，以及partition的leader
2. 根据consumer中的auto.offset.reset设置， consumer回到一个old offset的位置从leader中再次消费消息
3. .Leader根据offset等信息定位到segment（索引文件和日志文件）
4. 根据索引文件中的内容，定位到日志文件中该偏移量对应的开始位置读取相应长度的数据并返回给consumer

### 同步

每个topic都有1到N个分区，每个分区有多个replica，多个replica中有一个是Leader，其他都是follower，Leader负责响应producer和consumer的读写请求。一旦有数据写到Leader,则所有的Follower都会从Leader中去同步数据，但并非所有Follower都能及时同步，所以kafka将所有的replica分成两个组：ISR和OSR。ISR是与Leader数据同步的Follower，而OSR是与Leader数据不同步的Follower

**AR-**（Assigned Repllicas）分区中所有的副本

**ISR**-（In-Sync Replicas）所有与leader副本保持一定程度同步的副本（包括Leader）组成**ISR**

**OSR**-(Out-Sync Relipcas) 所有与leader副本滞后超过一定程度同步的副本。message—>leader,leader--->follwers.follwers相对于leader有一定程度的滞后。一定程度可以设定

**HW**-（high watemark）replica高水印值，副本中最新一条已提交消息的位移。leader 的HW值也就是实际已提交消息的范围，每个replica都有HW值，但仅仅leader中的HW才能作为标示信息。消费只能拉取到这个offset之前的消息。ISR集合中最小的LEO即为分区的HW

**LEO**-（log end offset）日志末端位移，也就是replica中下一条待写入消息的offset。

 Leader副本负责维护和跟踪ISR集合中所有的follower副本的滞后状态，当follower副本落后太多或者失效时，leader副本会吧它从ISR集合中剔除。如果OSR集合中follower副本“追上”了Leader副本，之后再ISR集合中的副本才有资格被选举为leader，而在OSR集合中的副本则没有机会

#### Broker收到消息后，做了什么

- broker 收到producer的请求 
- leader  收到消息，并成功写入，LEO 值+1 
- broker 将消息推给follower replica，follower 成功写入 LEO +1 … 
- 所有LEO 写入后，leader HW +1 
- 消息可被消费，并成功响应

同步给followers的数量由ack参数决定。

- -1——同步给所有的follower.
- 0——不需要同步给任何follower,记下消息后立马返回.
- 1——同步给一个follower就好。

KAFKA的消息保存在Topic中，Topic可分为多个分区，为保证数据的安全性，每个分区又有多个Replia，分区中分为leader和followers

#### **多分区的设计的特点**：

1.为了并发读写，加快读写速度；

2.是利用多分区的存储，利于数据的均衡；

3.是为了加快数据的恢复速率，一但某台机器挂了，整个集群只需要恢复一部分数据，可加快故障恢复的时间

### zk在kafka中的作用

- 注册broker

broker是**分布式独立部署**的，需要一个**注册中心**将整个broker**管理**联系起来。zk上专门有一个用来进行记录broker服务器列表记录的**节点**. broker启动时都到zk上进行注册,然后在brokers/ids下拆概念佳能自己的节点。记录自己的**ip地址和端口**信息。该节点是**临时**的，宕机时该节点也会被自动删除

```
/brokers/ids/[1-n]
```

- topic 注册

一个topic 对应多个分区。且分区均匀分布在多个broker。分区的信息和broker之间的关系也有zk维护。并由专门节点（/brokers/topics/[topic_name]）记录。broker启动后，会到对应的topic节点上注册自己的id并切入分区总数。

```
//代表topic=prioduct,id =3 的broker提供了2个分区。该分区节点也是临时节点
/brokers/topics/product/1->2
```

- 消费者注册

每个consumer 启动时，将消费者注册到消费组。会到zk的指定节点创建自己的消费者节点。节点创建后，消费者就会将自己订阅的Topic信息写入该临时节点

```
/consumers/[group_id]/ids/[consumer_id]
```

- 生产者负载均衡

producer 会将消息合理发送到broker上。使用zk进行负载均衡。broker启动时，会完成broker注册，producer 通过该节点的变化动态感知broker服务器列表的变化。可以动态实现负载均衡

- 消费者负载均衡

类似producer ,每个消费者分组包含若干消费者，**每条消息都只会发送给分组中的一个消费者**，不同的消费者分组消费自己特定的Topic下面的消息，互不干扰

- 分区与消费者

消费组中包含多个消费者。每个消费者都只有一个消费组。在zk上记录group 与consumer之间的关系，每个consumer一旦确定对一个partition的消费，将consumer id记录到zk上的临时节点上。

```
/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]
```

- 消息消费进度offset

消费时定时将消费进度offset记录到zk上，以便后续的消费

```
/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]
```

https://www.jianshu.com/p/a036405f989c