#### Myisam和InnoDB存储引擎的区别？

- **InnoDB 支持事务，MyISAM 不支持事务。**这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
- **InnoDB 支持外键，而MyISAM 不支持外键。**对一个包含外键的 InnoDB 表转为 MYISAM 会失败；
- **InnoDB 是聚集索引，MyISAM 是非聚集索引。**聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
- **InnoDB 不保存表的具体行数**，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；
- **InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。**一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一

#### UUID 与自增id

**uuid**:随机存储且空间大，性能较差，但保证唯一

**自增id**:数据在物理结构上是顺序存储，性能好，占用空间少。采用int和bigint分别是4和8字节。一般不会到达最大值，数据量太大 查询效果差应采用分库分表

#### 分布式分库分表如何确定ID

- 自增id：简单方便，但是不适合高并发
- uuid：生成简单，但是占用空间大且无序，不适合做id.可在数据库中再自增一个id
- 系统时间：高并发情况下可能重复，可使用系统时间+业务id或文件id来避免
- 雪花算法：通过snowflake生成的long类型id，在二进制下的长度总计64位

#### 间隙锁是什么？行锁升级为表锁的情况？

**间隙锁**:间隙锁一般发生在范围查询情况下。比如我们表中的数据，其`id`字段是按连续依次递增的，但如果不是连续的话，就会产生一些间隙(GAP)，这些间隙引发的锁就是间隙锁(NEXT-KEY)

比如有 id 为：1、3、5、7 的 4 条数据，我们查找 1-7 范围的数据。那么 1-7 都会被加上锁。2、4、6 也在 1-7 的范围中，但是不存在这些数据记录，这些 2、4、6 就被称为间隙。

**行锁升级表锁**：在不加索引的字段(除了主键以及唯一索引之外)上进行数据的加索,会升级为表锁 加了索引会正常输出。或者使用一些方式使得索引失效，锁升级

udpate user set age = 20 where id =1 or id=3//or 导致索引失效

#### 查看锁情况

```
SHOW STATUS LIKE 'innodb_row_lock%';
```

Innodb_row_lock_current_waits：表示有多少个SQL在等待锁。
Innodb_row_lock_time：表示锁的总耗费时间。
Innodb_row_lock_time_avg：表示锁的平均耗费时间。
Innodb_row_lock_time_max：表示锁的最大耗费时间。
Innodb_row_lock_waits：表示使用锁的次数

#### InnoDB的行锁有哪些？锁住的是行还是索引？

 行锁（Record Lock）:锁直接加在索引记录上面，锁住的是key，依赖的是索引

间隙锁（Gap Lock）:用范围条件请求共享或排他锁时，InnoDB会给符合条件的已有数据进行加锁； 对于键值在条件范围内但并不存在的记录，叫做 “间隙（GAP）”。间隙锁是针对事务隔离级别为RR或以上级别而已的。防止其他事务的插入操作，以此防止幻读的发生。一般针对为**非唯一索引**，前开后开。

临键锁（Next-Key Lock ）：record lock + gap lock, 前开后闭

锁住的是索引，而不是行

#### 何时产生间隙锁

- 更新条件没走索引，走全表扫描，进行表锁
- 更新条件走唯一索引，等值查询使用行锁，等值查询但是结果不存在或者范围查询使用Next-Key Lock
- 更新条件走普通索引。等值查询。数据不存在时加Next-Key Lock。数据存在时加Gap Lock
- 同时使用唯一索引和普通索引时，由于数据行是优先根据普通索引排序，再根据唯一索引排序，所以也会产生间隙锁

#### 为什么RR可以解决幻读？

RR下对读的行加锁，直到事务结束。但是当其他session 进行insert，会产生幻读，

- 在快照读（snapshot read）的情况下，MySQL通过MVCC（多版本并发控制）来避免幻读

  > 快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。主要应用于无需加锁的普通查询（select）操作

- 在当前读（current read）的情况下，MySQL通过next-key lock来避免幻读。

  > 当前读，读取的是记录的最新版本，并且会对当前记录加锁，防止其他事务发修改这条记录。加行共享锁、加行排他锁的操作都会用到当前度

例如：事务A 进行select * from user where name = 'lily' for update，加上了间隙锁。

​			事务B对user进行insert时，查看gap是否被锁住，锁住则无法insert.

#### 在RC（读已提交）和RR（可重复度）级别下，MVCC都会生效，那么为什么RC不可以解决幻读，而RR可以解决幻读？

innoDb有ReadView。readview中主要存有当前还活跃的事务m_ids.对于RR，事务开始时生成readview.对于RC,每次select 生成一个readview

> https://blog.csdn.net/qq_35634181/article/details/113280233

#### 事务并发问题

- 脏读：事务A读取了事务B未提交的数据。

- 不可重复度：事务A多次读取同一份数据，事务B在此过程中对数据修改并提交，导致事务A多次读取同一份数据的结果不一致。

- 幻读：事务A修改数据的同时，事务B插入了一条数据，当事务A提交后发现还有数据没被修改，产生了幻觉。

  **不可重复读侧重于update操作，幻读侧重于insert或delete。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。**

#### 事务隔离级别

- `读未提交（READ UNCOMMITTED）`：一个事务还没提交时，它做的变更就能被别的事务看到。
- `读提交（READ COMMITTED）`：一个事务提交之后，它做的变更才会被其他事务看到。
- `可重复读（REPEATABLE READ）`：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- `串行化（SERIALIZABLE）`：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”，当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

| 隔离级别         | 脏读 | 不可重复读 | 幻读 |
| :--------------- | :--- | :--------- | :--- |
| READ UNCOMMITTED | Yes  | Yes        | Yes  |
| READ COMMITTED   | No   | Yes        | Yes  |
| REPEATABLE READ  | No   | No         | Yes  |
| SERIALIZABLE     | No   | No         | No   |

默认RR.一致读快照（Read View）是在第一次SELECT发起时建立,之后不会发生变化

#### 如何理解Mysql默认的事务隔离级别可重复读？

主从复制这个层面说，mysql主从复制是基于binlog进行复制的，binlog有三种数据格式-statement、row、mixed.在mysql5.0版本之前，binlog只支持statement这种格式,在这种格式下，主从复制会出现主从不一致的问题。
解决方案：
1.隔离级别设为可重复读(Repeatable Read),在该隔离级别下引入间隙锁。当Session 1执行delete语句时，会锁住间隙。那么，Ssession 2执行插入语句就会阻塞住。
2.将binglog的格式修改为row格式，此时是基于行的复制，自然就不会出现sql执行顺序不一样的问题！奈何这个格式在mysql5.1版本开始才引入

#### 为什么mysql事务隔离级别是rc的情况下主从同步不一致

> https://blog.csdn.net/nanaranran/article/details/77719709

#### 事务的ACID属性是如何实现的？

原子性通过回滚日志undo log实现；

持久性通过重做日志redo log实现；

隔离性通过锁和MVCC实现；

一致性则是通过原子性、隔离性、持久性来实现，只有满足这三个特性，才能实现事务的一致性

#### 聚集索引

聚集索引的叶子节点中存储的是数据

#### 非聚集索引

非聚集索引的叶子节点存储的数据的指针

#### 回表查询

select * from user where name = "Tom"

步骤一：通过name的索引获取到对应的主键id值

步骤二：通过id查询聚簇索引查询具体的数据，叫回表查询

#### 覆盖索引

select name,age from user where name = "Tom"

项目中存在name和age 的索引树，如果只通过这个索引树就能得到所有的列就是覆盖索引，如果查询表里面的所有字段，则还需要回表查询出所有的字段。减少回表查询

#### 索引失效的情况？

(违反最左前缀法则、范围查询右边的列索引失效、字符串不加单引号、对索引列进行运算、头部模糊匹配、使用不等于！=或者<>)

#### mysql三大范式

1NF要求每列保持原子性，

2NF：消除部分依赖，即确保每列与主键相关，

3NF：消除传递依赖，即确保每列和逐渐直接相关，而不是间接相关，

#### B树与B+树差别

- b+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”，减少了磁盘 IO；
- b+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）；
- b+树叶子节点有连接，对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历

#### mysql索引的底层实现，为什么用B+树不用B树？

B+树的节点中不存储数据，能存储更多的节点，会降低高度，更矮胖，减少了IO，效率得到提升

B+树的叶子节点中存在链表、更适合范围查询、查询效率更加稳定

#### 哈希表查找速度不是更快吗，为什么不直接使用哈希表来做索引的底层数据结构

hash 底层时数组+链表的形势，可通过key准确查找到数据。但是hash 不是有序的，不支持范围查询

#### mysql的日志

- ##### 二进制日志bin log

  - 内容：逻辑格式的日志，记录执行过事务的sql
  - 作用：用于主从复制。或基于时间点的还原
  - MySQL Server层面的。
  - 追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。
  - 有三种格式  ：statement  row  mixed
    - statement:每一条会修改数据的sql都会记录在binlog中。5.0之前默认
      - 优点：相比较于row,不需要记录每行的变化，减少binog的数据量。带条件的update,整表delete,alter产生日志少。
      - 缺点：因为只记录执行语句，为了能在slave上正确运行。还必须记录每条语句在执行时的相关信息
    - row:不记录sql语句上下文相关信息，仅保存哪条记录被修改
      - 优点：正常同一条记录update.insert.row产生的日志量还小于statement
      - 缺点：带条件的update,整表delete,alter。row会产生大量日志。
    - mixed:以上两种混合。一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog。

- ##### 重做日志redo log

  - 内容：物理格式的日志，记录物理数据页的修改。用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。
  - 作用：确保事务的持久性。在实例或者介质失败时，使用redolog恢复掉断电时刻。
  - IinnoDB层面。先写日志再写更新内存
  - 循环写，日志空间大小固定

  redo log 什么时候记录

  ![img](D:\project\blog\docs\image\mysql\redolog.jpeg)

- ##### 回滚日志undo log

  - 内容：逻辑格式的日志，记录与操作相反的sql
  - 作用：确保事务的原子性。

  ![img](..\image\mysql\undolog.jpeg)

- ##### 一般查询日志 general log

  - 默认关闭
  - 内容： 记录的格式为 {Time ，Id ，Command，Argument }慢日志查询 slow query log
  - 作用：记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误，general log 都会将其记录下来

- ##### 慢日志查询 slow query log

  - 作用：记录执行时间过长和没有使用索引的查询语句

- ##### 错误日志 error log

  - 默认关闭，可通过配置将错误信息输出到某个地址

- ##### 中继日志 relay log

  - 作用：临时日志，只在主从分离的从节点上。用于存储从master节点同步过来的binlog日志内容，它里面的内容和master节点的binlog日志里面的内容是一致的。然后slave从节点从这个relaylog日志文件中读取数据应用到数据库中，来实现数据的主从复制

> 引用：https://www.sohu.com/a/316482862_663371

#### update user set name = 'tom' where id = 1的执行顺序

- 在内存中查找id=1的数据，如果有直接返回；如果没有，则从磁盘中读入内存，然后再返回
- 设置name的新值
- 将新数据更新到内存中，同时将这个更新操作记录到redo log,此时redo log处于**prepare**状态，然后告知执行器，可以随时提交事务
- 执行器生成这个操作的binlog,并把binlog写入磁盘
- 执行器提交事务，引擎将redolog改成commit状态，更新完成

#### 主从同步如何实现

- master提交完事务后，写入binlog

- slave连接到master，获取binlog

- master创建dump线程，推送binglog到slave

- slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中

- slave再开启一个sql线程读取relay log事件并在slave执行，完成同步

- slave记录自己的binglog

#### 表中有大字段，经常会查询到，不怎么更新，如何提升效率

拆分字段成子表。最好和经常要查询的表的主键在物理结构上放置在一起(分区) 顺序IO,减少连接消耗,最后这是一个文本列再加上一个全文索引来尽量抵消连接消耗

#### 一个6亿的表a，一个3亿的表b，通过外间tid关联，你如何最快的查询出满足条件的第50000到第50200中的这200条数据记录。

- 如果A表tid是自增长,并且是连续的,B表的ID为索引
  select * from a,b where a.tid = b.id and a.tid>500000 limit 200;

- 如果A表的TID不是连续的,那么就需要使用覆盖索引.TID要么是主键,要么是辅助索引,B表ID也需要有索引。
  select * from b , (select tid from a limit 50000,200) a where b.id = a .tid;